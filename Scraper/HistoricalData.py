from tvDatafeed import TvDatafeed, Interval
import pandas as pd
import json
import asyncio
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def get_historical_data(symbol):
    tv = TvDatafeed()

    bars_count = 1000  # approx 1 year daily bars

    # Fetch historical data: daily bars, for about 1 year
    historical_data = tv.get_hist(
        symbol=symbol,
        exchange='SET',
        interval=Interval.in_4_hour,
        n_bars=bars_count
    )

    historical_data = historical_data.copy()
    for col in historical_data.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, UTC]']).columns:
        historical_data[col] = historical_data[col].dt.strftime('%Y-%m-%dT%H:%M:%S')

    json_data = historical_data.reset_index().to_dict(orient='records')
    return json_data

tv = TvDatafeed()

def fetch_one_stock(row):
    symbol = row['symbol']
    thai_name = row['ThaiCompanyName']
    eng_name = row['EngCompanyName']
    logo = row['logo']

    logger.info(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {symbol} ({eng_name})")

    try:
        historical_data = tv.get_hist(
            symbol=symbol,
            exchange='SET',
            interval=Interval.in_4_hour,
            n_bars=2
        )

        if historical_data is None or historical_data.empty or len(historical_data) < 2:
            logger.warning(f"‚ö†Ô∏è {symbol} ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠")
            return {
                "stockSymbol": symbol,
                "ThaiCompanyName": thai_name,
                "EngCompanyName": eng_name,
                "logo": logo,
                "error": "No sufficient data"
            }

        last_close = historical_data['close'].iloc[-1]
        previous_close = historical_data['close'].iloc[-2]
        pct_change = ((last_close - previous_close) / previous_close) * 100

        logger.info(f"‚úÖ {symbol}: ‡∏£‡∏≤‡∏Ñ‡∏≤ {last_close} | ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á {pct_change:.2f}%")

        return {
            "stockSymbol": symbol,
            "ThaiCompanyName": thai_name,
            "companyName": eng_name,
            "logo": logo,
            "stockPrice": round(float(last_close), 2),
            "changePct": round(float(pct_change), 2)
        }

    except Exception as e:
        logger.error(f"‚ùå {symbol} ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        return {
            "stockSymbol": symbol,
            "ThaiCompanyName": thai_name,
            "EngCompanyName": eng_name,
            "logo": logo,
            "error": str(e)
        }

def get_stock_price(symbol_list):
    df = pd.read_csv("ThaiCompanyData.csv")

    # ‡∏Å‡∏£‡∏≠‡∏á dataframe ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÅ‡∏Ñ‡πà symbol ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    df_filtered = df[df['symbol'].str.upper().isin([s.upper() for s in symbol_list])]

    if df_filtered.empty:
        logger.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö symbol ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏")
        return []

    result = []

    logger.info(f"‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(df_filtered)} ‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤ ‡∏î‡πâ‡∏ß‡∏¢ ThreadPoolExecutor max_workers=3")

    with ThreadPoolExecutor(max_workers=3) as executor:
        futures = {executor.submit(fetch_one_stock, row): row['symbol'] for _, row in df_filtered.iterrows()}

        for future in as_completed(futures):
            res = future.result()
            result.append(res)

    logger.info("‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö‡πÅ‡∏•‡πâ‡∏ß")
    return result

async def async_fetch_one_stock(row):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, fetch_one_stock, row)

async def event_generator(symbol_list):
    df = pd.read_csv("ThaiCompanyData.csv")
    df_filtered = df[df['symbol'].str.upper().isin([s.upper() for s in symbol_list])]

    if df_filtered.empty:
        yield f"data: {json.dumps({'error': 'No symbols found'})}\n\n"
        return

    batch_size = 2
    rows = list(df_filtered.iterrows())

    for i in range(0, len(rows), batch_size):
        batch_rows = rows[i:i + batch_size]

        tasks = [async_fetch_one_stock(row) for _, row in batch_rows]
        results = await asyncio.gather(*tasks)  # ‡∏î‡∏∂‡∏á‡∏ó‡∏µ‡∏•‡∏∞ 2 ‡∏ï‡∏±‡∏ß‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô

        for res in results:
            yield f"data: {json.dumps(res)}\n\n"

    # Keep connection alive
    while True:
        await asyncio.sleep(15)
        yield ":\n\n"  # SSE comment keep-alive

def get_cron_stock_price(symbol_list, max_retries=1000):
    import time

    df = pd.read_csv("ThaiCompanyData.csv")
    df_filtered = df[df['symbol'].str.upper().isin([s.upper() for s in symbol_list])]

    if df_filtered.empty:
        logger.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö symbol ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏")
        return [], []

    result = []
    failed_symbols = []

    logger.info(f"‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(df_filtered)} ‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤ ‡∏î‡πâ‡∏ß‡∏¢ ThreadPoolExecutor max_workers=3")

    for attempt in range(1, max_retries + 1):
        current_result = []
        current_failed = []

        logger.info(f"üì¶ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏≠‡∏ö‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Attempt #{attempt}")

        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = {
                executor.submit(fetch_one_stock, row): row['symbol']
                for _, row in df_filtered.iterrows()
            }

            for future in as_completed(futures):
                symbol = futures[future]
                try:
                    res = future.result()

                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ res ‡∏°‡∏µ error ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
                    if isinstance(res, dict) and res.get("error"):
                        logger.warning(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {symbol} ‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå (error field): {res['error']}")
                        current_failed.append(symbol)
                    else:
                        current_result.append(res)

                except Exception as e:
                    logger.warning(f"‚ùå ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {symbol} ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÉ‡∏ô Attempt #{attempt}: {e}")
                    current_failed.append(symbol)

        result.extend(current_result)
        logger.info(f"‚úÖ Attempt #{attempt}: ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à {len(current_result)} ‡∏ï‡∏±‡∏ß | ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß {len(current_failed)} ‡∏ï‡∏±‡∏ß")

        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß -> ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å Loop
        if not current_failed:
            break

        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ï‡∏±‡∏ß‡∏ß‡∏ô‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà fail
        df_filtered = df[df['symbol'].str.upper().isin([s.upper() for s in current_failed])]
        failed_symbols = current_failed

        time.sleep(1)  # Optional: ‡∏û‡∏±‡∏Å‡∏™‡∏±‡∏Å‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡πà‡∏≠‡∏ô Retry ‡∏£‡∏≠‡∏ö‡∏ñ‡∏±‡∏î‡πÑ‡∏õ

    return result, failed_symbols

